{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b94190f-4baf-4f33-801f-69915eb3a24a",
   "metadata": {},
   "source": [
    "# Airline Customer Tweets Data for Sentiment Analysis using Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8458e-fb69-44ff-89ac-da738d062d06",
   "metadata": {},
   "source": [
    "This project uses Twitter API to gather customer tweets from various airline handles operating in the USA. The tweets are then analyzed using the Google Cloud Natural Language API to understand the sentiment towards each airline. The data collection is automated to run daily for a month, with the results stored in a file named `/airline_twitter.csv`. An exploratory analysis will be conducted using a separate notebook to gain deeper insights into customer sentiments towards each airline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7e757-2fc3-4f79-840f-880acc12628c",
   "metadata": {},
   "source": [
    "## Dataset License\n",
    "\n",
    "**CC BY-NC: Creative Commons Attribution-NonCommercial 4.0 International License**\n",
    "\n",
    "This license is one of the Creative Commons licenses and allows users to share and adapt the dataset if they give credit to the copyright holder and do not use the dataset for any commercial purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c74530-440d-46b0-91a0-f5640ae4511c",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "**A Note to Users and Readers**\n",
    "\n",
    "* I'd appreciate receiving your feedbacks in comments and messages.\n",
    "* To run this notebook, you will have to request API credentials from Twitter and Google Cloud.\n",
    "* You are allowed to download and use the dataset only for non-commercial purposes and with proper attribution. (Read Twitter Developer Guidelines for more info).\n",
    "* A detailed EDA will be presented in a separate Notebook.\n",
    "\n",
    "**Comment on Sentiment Score and Magnitude Accuracy**\n",
    "* The sentiment score and magnitude was calculated by Google Cloud Natural Languaging API, that is easy to use and highly accurate. It uses machine learning models that have been trained on large amounts of data, and it can perform a wide range of natural language processing tasks, including sentiment analysis. It also offers pre-trained models that can be used out-of-the-box.\n",
    "* I have used Google's NL API because of the following reason:\n",
    "    - I didn't have the labeled data for training the model. Google NL API ML models are pre-trained on large amount of datasets.\n",
    "    - Google NL API models are highly accurate models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4401c89-b084-4eda-a6e1-62c8a25dced0",
   "metadata": {},
   "source": [
    "## Table of Contents for Code Cells\n",
    "\n",
    "1. Import Libraries\n",
    "2. Configure objects to Authenticate with Twitter API\n",
    "3. Define Functions  \n",
    "A. Read Google Cloud API Project Credentials  \n",
    "B. Translate non-English Tweet Text to English  \n",
    "C. Preprocess and Clean the Tweets Texts  \n",
    "D. Obtain User Locations from the Tweets  \n",
    "E. Analyze Tweet Sentiment  \n",
    "F. Write Twitter Data and Sentiment Data to CSV File  \n",
    "G. Read Airline Twitter Handles Stored in a JSON File  \n",
    "H. Search Today's 100 Tweets for Each Airline  \n",
    "4. Call Functions for the Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d31ce0-2e88-4cbc-aa42-b9dfe24fe73f",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ca26c-13cc-4177-88dc-57c11ec7eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import twitter_api_keys as keys\n",
    "import tweepy\n",
    "from google.cloud import translate, language_v1\n",
    "import preprocessor as p\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebdfc7-094a-4db6-ab22-3d2f78f1a9b7",
   "metadata": {},
   "source": [
    "## 2. Configure objects to Authenticate with Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f3733-71b5-4626-9eab-eac48c899943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and Configuring an OAuthHandler to Authenticate with Twitter\n",
    "auth = tweepy.OAuthHandler(keys.consumer_key,\n",
    "                           keys.consumer_secret)\n",
    "\n",
    "auth.set_access_token(keys.access_token,\n",
    "                      keys.access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c9bf0-5492-4230-b9d6-74b8cf9b463a",
   "metadata": {},
   "source": [
    "## 3. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58337b46-6730-4956-97b7-4ba5d6432f47",
   "metadata": {},
   "source": [
    "### A. Read Google Cloud API Project Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ea917-6c0d-4a05-9c5f-534b03462908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_translate_api():\n",
    "    \"\"\"This function read secured project credentials and keys for Google\n",
    "    Cloud API from json file and return the parent object to interact\n",
    "    with Google API.\n",
    "    (Read Google documentation for more info on set-up and usage of\n",
    "    Google Cloud API libraries.)\n",
    "    \"\"\"\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS']='./google_cloud_api.json'\n",
    "    os.environ['PROJECT_ID'] = keys.project_id\n",
    "    project_id = os.environ.get(\"PROJECT_ID\", \"\")\n",
    "    assert project_id\n",
    "    parent = f\"projects/{project_id}\"\n",
    "\n",
    "    return parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70d7ab-afe6-4abf-94b3-e1f8614d4cdd",
   "metadata": {},
   "source": [
    "### B. Translate non-English Tweet Text to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f775a34-6c87-4eed-8735-84d884fdc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_tweet_text(parent, tweet, tweet_text):\n",
    "    \"\"\"If tweet language is not English, translate the tweet\n",
    "    text to English using Google Cloud Translate API library\n",
    "    and return the translated text.\n",
    "    \"\"\"\n",
    "    if 'en' in tweet.lang:\n",
    "        # return tweets as it is, if already in English language\n",
    "        return tweet_text\n",
    "\n",
    "    elif 'und' not in tweet.lang:  # translate to English first\n",
    "        # Use Google Translate API to translate tweet\n",
    "        client = translate.TranslationServiceClient()\n",
    "        response = client.translate_text(\n",
    "            contents=[tweet_text],\n",
    "            target_language_code=\"en\",\n",
    "            parent=parent\n",
    "        )        \n",
    "        # return tweet translated to English language\n",
    "        return response.translations[0].translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc5dd8-c461-4b43-afe0-0c38c85cb4de",
   "metadata": {},
   "source": [
    "### C. Preprocess and Clean the Tweet Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4899e79-0449-4207-b300-1a4ea45ed312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet_text(tweet_text):\n",
    "    \"\"\"Removes the URLs, hashtags, and @mentions from the tweet text\n",
    "    and returns the clean text.\"\"\"\n",
    "    \n",
    "    # Tweets cleaning and pre-processing\n",
    "    # remove URLs and Twitter reserved words, e.g. RT, FAV\n",
    "    p.set_options(p.OPT.URL, p.OPT.RESERVED)\n",
    "    p.clean(tweet_text)\n",
    "    tweet_text = re.sub(r\"http\\S+\", '', tweet_text)\n",
    "    tweet_text = re.sub(r'#\\w+', '', tweet_text)\n",
    "    tweet_text = re.sub(r'@\\w+', '', tweet_text)\n",
    "\n",
    "    return tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74960ab-e9b7-46d7-98d6-d892ad1f7411",
   "metadata": {},
   "source": [
    "### D. Obtain User Locations from the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88d5a5-4088-4d29-981f-7934de6d9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_location(tweet):\n",
    "    \"\"\"Returns the location of the tweet, if available.\"\"\"\n",
    "    if tweet.place is not None:\n",
    "        return tweet.place.name\n",
    "\n",
    "    else:\n",
    "        return \"Location not available\"\n",
    "\n",
    "def get_user_timezone(tweet):\n",
    "    \"\"\"Returns the timezone of the user, if available.\"\"\"\n",
    "    if tweet.user.time_zone is not None:\n",
    "        return tweet.user.time_zone\n",
    "\n",
    "    else:\n",
    "        return \"Time zone not available\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb7484-6843-4d82-bc3d-c769c5a96aea",
   "metadata": {},
   "source": [
    "### E. Analyze Tweet Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edc9b4-da94-482a-a60e-d759312a906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(tweet_text):\n",
    "    \"\"\"Performs sentiment analysis on tweets using the Google\n",
    "    Cloud Natural Language API and returns a list of tuples\n",
    "    containing the sentiment score and sentiment magnitude.\n",
    "    \"\"\"\n",
    "    # print(\"Length of tweet text = \", len(tweet_text))\n",
    "\n",
    "    min_length = 20\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=tweet_text,\n",
    "        type=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "\n",
    "    response = client.analyze_sentiment(request={\"document\":document})\n",
    "    sentiment = response.document_sentiment\n",
    "    score = sentiment.score\n",
    "    magnitude = sentiment.magnitude\n",
    "    results = (score, magnitude)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfa3f1-a46e-440f-aa20-66e239fdb4b8",
   "metadata": {},
   "source": [
    "### F. Write Twitter Data and Sentiment Data to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd827cf0-6934-4aef-9807-d9f5126f4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(parent, tweets, airline_name):\n",
    "    \"\"\"Write the data to a csv file /airline_twitter.csv.\"\"\"\n",
    "    file = \"./airline_twitter.csv\"\n",
    "    headers = ['airline', 'tweet_text', 'date', 'score', 'magnitude', 'user', 'retweet_count', 'likes_count', 'location', 'time_zone']\n",
    "    mode = 'w'\n",
    "    count = 0\n",
    "\n",
    "    if os.path.exists(file):\n",
    "        mode = 'a'\n",
    "\n",
    "    with open(file, mode, encoding='utf-8', newline='') as f:\n",
    "        writetweet = csv.writer(f)\n",
    "\n",
    "        if mode == 'w':\n",
    "            writetweet.writerow(headers)            \n",
    "\n",
    "        for tweet in tweets:\n",
    "\n",
    "            if tweet:\n",
    "                if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "                    \n",
    "                    tweet_text = tweet.full_text\n",
    "\n",
    "                    # Clean tweet text\n",
    "                    if tweet_text:\n",
    "                        tweet_text = preprocess_tweet_text(tweet_text)\n",
    "                    else:\n",
    "                        tweet_text=\"\"\n",
    "\n",
    "                    # Translate tweet to English first\n",
    "                    tweet_text = translate_tweet_text(parent, tweet, tweet_text)\n",
    "                    \n",
    "                    if tweet_text is not None:\n",
    "                        # Get sentiment analysis scores using Google API\n",
    "                        score, magnitude = analyze_sentiment(tweet_text)\n",
    "                        score = round(score, 3)\n",
    "                        magnitude = round(magnitude, 3)\n",
    "\n",
    "                    else:\n",
    "                        # Skipping sentiment analysis on this tweet\n",
    "                        score, magnitude = None, None\n",
    "                        print(f'Skipping sentiment analysis of tweet with text \"{tweet_text}\" because it is too short.')\n",
    "\n",
    "\n",
    "                    # Get tweet location\n",
    "                    tweet_loc = get_user_location(tweet)\n",
    "\n",
    "                    # Get tweet timezone\n",
    "                    tweet_tz = get_user_timezone(tweet)\n",
    "\n",
    "                    # Write data to csv file\n",
    "                    writetweet.writerow([airline_name,\n",
    "                                         tweet_text,\n",
    "                                         tweet.created_at,\n",
    "                                         score,\n",
    "                                         magnitude,\n",
    "                                         tweet.user.screen_name,\n",
    "                                         tweet.retweet_count,\n",
    "                                         tweet.favorite_count,\n",
    "                                         tweet_loc,\n",
    "                                         tweet_tz\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa440e-6a31-49fe-a296-aedbc0a5fa98",
   "metadata": {},
   "source": [
    "### G. Read Airline Twitter Handles Stored in a JSON File\n",
    "\n",
    "**Note**: This function requires `us_airlines.json` file. It is attached as a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184e838-6acb-4548-82a1-db523390612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_filepath):\n",
    "    \"\"\"Reads the airline names and their corresponding Twitter handles\n",
    "    from the JSON file and returns the result as a dictionary.\n",
    "    Note: Download \"us_airlines.json\" file along with this notebook.\n",
    "    \"\"\"\n",
    "    with open(json_filepath, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e2c74-dc1e-42c7-af24-a00df096425b",
   "metadata": {},
   "source": [
    "### H. Search Today's 100 Tweets for Each Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720e67e-4dc7-41bb-9c88-8ae413314770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(api, query):\n",
    "    \"\"\"Searches for tweets matching the given query, and returns the first 100 tweets from today\"\"\"\n",
    "    today = datetime.datetime.now().date()\n",
    "    since = today.strftime(\"%Y-%m-%d\")\n",
    "    until = (today + datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    tweets = []\n",
    "    print(f\"Run date: {today}\")\n",
    "    \n",
    "    try:\n",
    "        tweets = api.search_tweets(q=query+' -is:retweet', tweet_mode='extended', since=since, until=until, count=100)\n",
    "    except tweepy.error.TweepError as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782da3b-f54c-408d-8814-681b91aa8faf",
   "metadata": {},
   "source": [
    "## 4. Call Functions for the Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915b91-db85-4ed0-abc0-0b61925609b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an API object\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Get google translate api Parent parameter\n",
    "parent = google_translate_api()\n",
    "\n",
    "# Get all US airlines' Twitter handle from the json file.\n",
    "us_airlines = read_json('us_airlines.json')\n",
    "\n",
    "for key, value in us_airlines.items():\n",
    "    if value != None:\n",
    "        print(f\"Writing {key} data to file\")\n",
    "\n",
    "        # Search 100 tweets for each US airline\n",
    "        # tweets = api.search_tweets(q=value+' -is:retweet', tweet_mode='extended', count=100)\n",
    "\n",
    "        # Use the next code line from tomorrow 1/19/23 onwards and comment the above code line.\n",
    "        tweets = search_tweets(api=api, query=value)\n",
    "\n",
    "        # Write the tweet data to csv file.\n",
    "        write_to_csv(parent, tweets, airline_name=key)\n",
    "\n",
    "print(\"Writing to file COMPLETED.\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
